Here's my personal list of blogs which i find interesting. If you do too, we can have a coffee chat about them !!


### [LLM App arcihtecture ](https://medium.com/@terrycho/llm-application-architecture-b5e4425c73e1)
**Description:** How mordern day a LLM apps are build by architecture. 
**Category:** LLM Applications

### [The LLM App arcihtecture - github ](https://github.blog/ai-and-ml/llms/the-architecture-of-todays-llm-applications/)
**Description:** How mordern day a LLM apps are build by architecture. 
**Category:** Choose from the categories listed above.


## Best practices for building Generative AI applications 

### [Prompt Engineering](https://outshift.cisco.com/blog/prompt-engineering-techniques-genai-power-users)

1. ### [**A Guide to LLM orchestration**](https://orq.ai/blog/llm-orchestration)
2. ### [**RAG in Production: Deployment Strategies and Practical Considerations**](https://coralogix.com/ai-blog/rag-in-production-deployment-strategies-and-practical-considerations/)
3. ### [Building A Generative AI Platform](https://huyenchip.com/2024/07/25/genai-platform.html)
4. ### [LLMOps](https://www.swaroopch.com/llmops#11b0924249b180b29299c6ee8494eaf4)


### ðŸŸ¢ Core GenAI Integration Skills

| Skill | Use Case Example |
|-------|-----------------|
| **Prompt Engineering** | Designing and iteratively refining prompts to maximize accuracy and relevance in LLM-powered features, such as using prompt templates for code generation or troubleshooting[1]. |
| **RAG Pipeline Development** | Building and deploying Retrieval-Augmented Generation systems that combine vector database search (e.g., Pinecone, pgvector) with LLMs to deliver up-to-date, context-aware answersâ€”e.g., connecting company docs to ChatGPT for internal knowledge bots[2]. |
| **LLM Orchestration (LangChain, LlamaIndex, Orq.ai)** | Managing multi-step workflows, chaining prompts, integrating APIs, and handling fallback logic for robust GenAI applicationsâ€”e.g., orchestrating document search and summarization in enterprise apps[3]. |
| **AI-Native Cloud Services (AWS Bedrock, Azure OpenAI, GCP Vertex AI)** | Leveraging managed cloud platforms for scalable, secure, and compliant LLM deployment, including model selection, versioning, and monitoring[4][3]. |
| **Vector Database Integration** | Architecting and maintaining scalable vector stores for fast, accurate retrieval in RAG systemsâ€”e.g., sharding Pinecone for low-latency semantic search[2]. |
